{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project notebook\n",
    "\n",
    "The following notebook is an excerpt and re-written example from a _real_ production model.\n",
    "\n",
    "The overall purpose of the ML algorithm is to identify users on the website that are new possible customers. This is done by collecting behaviour data from the users as input, and the target is whether they converted/turned into customers -- essentially a classification problem. \n",
    "\n",
    "This notebook only focuses on the data processing part. As you know, there are multiple steps in an ML pipeline, and it's not always they are neatly separated like this. For the exam project, they will not be, and that is part of the challenge for you. For production code, it should also not be Python notebooks since, as you may well see, it is difficult to work with and collaborate on them in an automated way.\n",
    "\n",
    "There is a lot of \"fluff\" in such a notebook. This ranges from comments and markdown cells to commented out code and random print statements. That is not necessary in a properly managed project where you can use git to check the version history and such. \n",
    "\n",
    "What is important for you is the identify the entry points into the code and segment them out into easily understandable chunks. Additionally, you might want to follow some basic code standards, such as:\n",
    "\n",
    "- Import only libraries in the beginning of the files\n",
    "- Define functions in the top of the scripts, or if used multiple places, move into a util.py script or such\n",
    "- Remove unused/commented out code\n",
    "- Follow the [PEP 8](https://peps.python.org/pep-0008/) style guide (and others)\n",
    "  \n",
    "Another thing to note is that comments can be misleading. Even if the markdown cell or inline comments says it does _X_, don't be surprised if it actually does _Y_. Sometimes additional text can be a blessing, but it can also be a curse sometimes. Remember, though, that your task is to make sure the code runs as before after refactoring the notebook into other files, not update/improve the model or flow to reflect what the comments might say.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PROCESSING\n",
    "\n",
    "In this section, we will perform Exploratory Data Analysis (EDA) to better understand the dataset before proceeding with more advanced analysis. EDA helps us get a sense of the data’s structure, identify patterns, and spot any potential issues like missing values or outliers. By doing so, we can gain a clearer understanding of the data's key characteristics.\n",
    "\n",
    "We will start with summary statistics to review basic measures like mean, median, and variance, providing an initial overview of the data distribution. Then, we’ll create visualizations such as histograms, box plots, and scatter plots to explore relationships between variables, check for any skewness, and highlight outliers.\n",
    "\n",
    "The purpose of this EDA is to ensure that the dataset is clean and well-structured for further analysis. This step also helps us identify any necessary data transformations and informs decisions on which features might be most relevant for modeling in later stages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create artifact directory\n",
    "We want to create a directory for storing all the artifacts in the current directory. Users can load all the artifacts later for data cleaning pipelines and inferencing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dbutils.widgets.text(\"Training data max date\", \"2024-01-31\")\n",
    "# dbutils.widgets.text(\"Training data min date\", \"2024-01-01\")\n",
    "# max_date = dbutils.widgets.get(\"Training data max date\")\n",
    "# min_date = dbutils.widgets.get(\"Training data min date\")\n",
    "\n",
    "# testnng\n",
    "max_date = \"2024-01-31\"\n",
    "min_date = \"2024-01-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created artifacts directory\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pprint import pprint\n",
    "\n",
    "# shutil.rmtree(\"./artifacts\",ignore_errors=True)\n",
    "os.makedirs(\"artifacts\",exist_ok=True)\n",
    "print(\"Created artifacts directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas dataframe print options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.float_format',lambda x: \"%.3f\" % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions\n",
    "\n",
    "* **describe_numeric_col**: Calculates various descriptive stats for a numeric column in a dataframe.\n",
    "* **impute_missing_values**: Imputes the mean/median for numeric columns or the mode for other types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_numeric_col(x):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        x (pd.Series): Pandas col to describe.\n",
    "    Output:\n",
    "        y (pd.Series): Pandas series with descriptive stats. \n",
    "    \"\"\"\n",
    "    return pd.Series(\n",
    "        [x.count(), x.isnull().count(), x.mean(), x.min(), x.max()],\n",
    "        index=[\"Count\", \"Missing\", \"Mean\", \"Min\", \"Max\"]\n",
    "    )\n",
    "\n",
    "def impute_missing_values(x, method=\"mean\"):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        x (pd.Series): Pandas col to describe.\n",
    "        method (str): Values: \"mean\", \"median\"\n",
    "    \"\"\"\n",
    "    if (x.dtype == \"float64\") | (x.dtype == \"int64\"):\n",
    "        x = x.fillna(x.mean()) if method==\"mean\" else x.fillna(x.median())\n",
    "    else:\n",
    "        x = x.fillna(x.mode()[0])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data\n",
    "\n",
    "We read the latest data from our data lake source. Here we load it locally after having pulled it from DVC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything is up to date.\n"
     ]
    }
   ],
   "source": [
    "!dvc pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data\n",
      "Total rows: lead_id                              12345\n",
      "lead_indicator                       11753\n",
      "date_part                            12345\n",
      "is_active                            12345\n",
      "marketing_consent                    12345\n",
      "first_booking                        12345\n",
      "existing_customer                    12345\n",
      "last_seen                            12345\n",
      "source                               12345\n",
      "domain                               12345\n",
      "country                              12345\n",
      "visited_learn_more_before_booking    12345\n",
      "visited_faq                          12345\n",
      "purchases                            12345\n",
      "time_spent                           12345\n",
      "customer_group                       12345\n",
      "onboarding                           12345\n",
      "customer_code                        12294\n",
      "n_visits                             12345\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lead_id</th>\n",
       "      <th>lead_indicator</th>\n",
       "      <th>date_part</th>\n",
       "      <th>is_active</th>\n",
       "      <th>marketing_consent</th>\n",
       "      <th>first_booking</th>\n",
       "      <th>existing_customer</th>\n",
       "      <th>last_seen</th>\n",
       "      <th>source</th>\n",
       "      <th>domain</th>\n",
       "      <th>country</th>\n",
       "      <th>visited_learn_more_before_booking</th>\n",
       "      <th>visited_faq</th>\n",
       "      <th>purchases</th>\n",
       "      <th>time_spent</th>\n",
       "      <th>customer_group</th>\n",
       "      <th>onboarding</th>\n",
       "      <th>customer_code</th>\n",
       "      <th>n_visits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2024-01-24</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-01-25</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-01-13</td>\n",
       "      <td>organic</td>\n",
       "      <td>.dk</td>\n",
       "      <td>US</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>115.064</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-01-1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-01-24</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-01-6</td>\n",
       "      <td>signup</td>\n",
       "      <td>.dk</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>119.907</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>AGMVEYWACO</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2024-01-27</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-01-30</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-01-30</td>\n",
       "      <td>signup</td>\n",
       "      <td>.dk</td>\n",
       "      <td>DK</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>100.474</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>STWPXVNOWA</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2024-01-28</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-01-10</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-01-11</td>\n",
       "      <td>li</td>\n",
       "      <td>.cn</td>\n",
       "      <td>US</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>98.572</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>HZOKZERLZD</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2024-01-5</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-01-30</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-01-25</td>\n",
       "      <td>fb</td>\n",
       "      <td>.com</td>\n",
       "      <td>US</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>101.996</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>CVLIHCAPZN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lead_id  lead_indicator   date_part  is_active  marketing_consent  \\\n",
       "0        0           0.000  2024-01-24          0               True   \n",
       "1        1             NaN   2024-01-1          1               True   \n",
       "2        2           1.000  2024-01-27          0               True   \n",
       "3        3           1.000  2024-01-28          0              False   \n",
       "4        4           0.000   2024-01-5          0               True   \n",
       "\n",
       "  first_booking  existing_customer   last_seen   source domain country  \\\n",
       "0    2024-01-25              False  2024-01-13  organic    .dk      US   \n",
       "1    2024-01-24              False   2024-01-6   signup    .dk      US   \n",
       "2    2024-01-30               True  2024-01-30   signup    .dk      DK   \n",
       "3    2024-01-10              False  2024-01-11       li    .cn      US   \n",
       "4    2024-01-30               True  2024-01-25       fb   .com      US   \n",
       "\n",
       "   visited_learn_more_before_booking  visited_faq  purchases  time_spent  \\\n",
       "0                                  8           10          5     115.064   \n",
       "1                                  0            3          5     119.907   \n",
       "2                                  7           10          3     100.474   \n",
       "3                                 10           10          4      98.572   \n",
       "4                                  5            1          5     101.996   \n",
       "\n",
       "   customer_group  onboarding customer_code  n_visits  \n",
       "0               2        True           NaN         9  \n",
       "1               2       False    AGMVEYWACO         1  \n",
       "2               5       False    STWPXVNOWA        16  \n",
       "3               4        True    HZOKZERLZD        16  \n",
       "4               9       False    CVLIHCAPZN         2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Loading training data\")\n",
    "\n",
    "data = pd.read_csv(\"./artifacts/raw_data.csv\")\n",
    "\n",
    "print(\"Total rows:\", data.count())\n",
    "display(data.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "if not max_date:\n",
    "    max_date = pd.to_datetime(datetime.datetime.now().date()).date()\n",
    "else:\n",
    "    max_date = pd.to_datetime(max_date).date()\n",
    "\n",
    "min_date = pd.to_datetime(min_date).date()\n",
    "\n",
    "# Time limit data\n",
    "data[\"date_part\"] = pd.to_datetime(data[\"date_part\"]).dt.date\n",
    "data = data[(data[\"date_part\"] >= min_date) & (data[\"date_part\"] <= max_date)]\n",
    "\n",
    "min_date = data[\"date_part\"].min()\n",
    "max_date = data[\"date_part\"].max()\n",
    "date_limits = {\"min_date\": str(min_date), \"max_date\": str(max_date)}\n",
    "with open(\"./artifacts/date_limits.json\", \"w\") as f:\n",
    "    json.dump(date_limits, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection\n",
    "\n",
    "Not all columns are relevant for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(\n",
    "    [\n",
    "        \"is_active\", \"marketing_consent\", \"first_booking\", \"existing_customer\", \"last_seen\"\n",
    "    ],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing columns that will be added back after the EDA\n",
    "data = data.drop(\n",
    "    [\"domain\", \"country\", \"visited_learn_more_before_booking\", \"visited_faq\"],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning\n",
    "* Remove rows with empty target variable\n",
    "* Remove rows with other invalid column data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target value counter\n",
      "0.0 :  0.5318352059925093\n",
      "1.0 :  0.4681647940074906\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lead_id</th>\n",
       "      <th>lead_indicator</th>\n",
       "      <th>date_part</th>\n",
       "      <th>source</th>\n",
       "      <th>purchases</th>\n",
       "      <th>time_spent</th>\n",
       "      <th>customer_group</th>\n",
       "      <th>onboarding</th>\n",
       "      <th>customer_code</th>\n",
       "      <th>n_visits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2024-01-27</td>\n",
       "      <td>signup</td>\n",
       "      <td>3</td>\n",
       "      <td>100.474</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>STWPXVNOWA</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2024-01-11</td>\n",
       "      <td>signup</td>\n",
       "      <td>8</td>\n",
       "      <td>105.899</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>JWLXPVANUM</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2024-01-22</td>\n",
       "      <td>signup</td>\n",
       "      <td>6</td>\n",
       "      <td>86.717</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>WNKCTHUHYI</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2024-01-07</td>\n",
       "      <td>signup</td>\n",
       "      <td>5</td>\n",
       "      <td>106.952</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>INIQMTGGOO</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2024-01-20</td>\n",
       "      <td>signup</td>\n",
       "      <td>3</td>\n",
       "      <td>94.668</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>SJGDAANOYJ</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12328</th>\n",
       "      <td>12328</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>signup</td>\n",
       "      <td>2</td>\n",
       "      <td>98.999</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>AYAVVZAMGV</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12330</th>\n",
       "      <td>12330</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>signup</td>\n",
       "      <td>6</td>\n",
       "      <td>101.390</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>YFKCVZSAJF</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12334</th>\n",
       "      <td>12334</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2024-01-21</td>\n",
       "      <td>signup</td>\n",
       "      <td>1</td>\n",
       "      <td>93.840</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>ROVGLTVJNL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12337</th>\n",
       "      <td>12337</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2024-01-03</td>\n",
       "      <td>signup</td>\n",
       "      <td>0</td>\n",
       "      <td>110.320</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>BGQNNVRTDH</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12343</th>\n",
       "      <td>12343</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2024-01-29</td>\n",
       "      <td>signup</td>\n",
       "      <td>8</td>\n",
       "      <td>105.713</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>UNUSNTTYXR</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2937 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       lead_id  lead_indicator   date_part  source  purchases  time_spent  \\\n",
       "2            2           1.000  2024-01-27  signup          3     100.474   \n",
       "10          10           0.000  2024-01-11  signup          8     105.899   \n",
       "13          13           0.000  2024-01-22  signup          6      86.717   \n",
       "17          17           1.000  2024-01-07  signup          5     106.952   \n",
       "19          19           0.000  2024-01-20  signup          3      94.668   \n",
       "...        ...             ...         ...     ...        ...         ...   \n",
       "12328    12328           1.000  2024-01-01  signup          2      98.999   \n",
       "12330    12330           1.000  2024-01-14  signup          6     101.390   \n",
       "12334    12334           0.000  2024-01-21  signup          1      93.840   \n",
       "12337    12337           1.000  2024-01-03  signup          0     110.320   \n",
       "12343    12343           1.000  2024-01-29  signup          8     105.713   \n",
       "\n",
       "       customer_group  onboarding customer_code  n_visits  \n",
       "2                   5       False    STWPXVNOWA        16  \n",
       "10                  4        True    JWLXPVANUM         4  \n",
       "13                  6        True    WNKCTHUHYI         5  \n",
       "17                  8       False    INIQMTGGOO         8  \n",
       "19                  9        True    SJGDAANOYJ        20  \n",
       "...               ...         ...           ...       ...  \n",
       "12328               5        True    AYAVVZAMGV        14  \n",
       "12330               4        True    YFKCVZSAJF        18  \n",
       "12334               5        True    ROVGLTVJNL         1  \n",
       "12337               6        True    BGQNNVRTDH        18  \n",
       "12343               8        True    UNUSNTTYXR        18  \n",
       "\n",
       "[2937 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data[\"lead_indicator\"].replace(\"\", np.nan, inplace=True)\n",
    "data[\"lead_id\"].replace(\"\", np.nan, inplace=True)\n",
    "data[\"customer_code\"].replace(\"\", np.nan, inplace=True)\n",
    "\n",
    "data = data.dropna(axis=0, subset=[\"lead_indicator\"])\n",
    "data = data.dropna(axis=0, subset=[\"lead_id\"])\n",
    "\n",
    "data = data[data.source == \"signup\"]\n",
    "result=data.lead_indicator.value_counts(normalize = True)\n",
    "\n",
    "print(\"Target value counter\")\n",
    "for val, n in zip(result.index, result):\n",
    "    print(val, \": \", n)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create categorical data columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed lead_id to object type\n",
      "Changed lead_indicator to object type\n",
      "Changed customer_group to object type\n",
      "Changed onboarding to object type\n",
      "Changed source to object type\n",
      "Changed customer_code to object type\n"
     ]
    }
   ],
   "source": [
    "vars = [\n",
    "    \"lead_id\", \"lead_indicator\", \"customer_group\", \"onboarding\", \"source\", \"customer_code\"\n",
    "]\n",
    "\n",
    "for col in vars:\n",
    "    data[col] = data[col].astype(\"object\")\n",
    "    print(f\"Changed {col} to object type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate categorical and continuous columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Continuous columns: \n",
      "\n",
      "['purchases', 'time_spent', 'n_visits']\n",
      "\n",
      " Categorical columns: \n",
      "\n",
      "[   'lead_id',\n",
      "    'lead_indicator',\n",
      "    'date_part',\n",
      "    'source',\n",
      "    'customer_group',\n",
      "    'onboarding',\n",
      "    'customer_code']\n"
     ]
    }
   ],
   "source": [
    "cont_vars = data.loc[:, ((data.dtypes==\"float64\")|(data.dtypes==\"int64\"))]\n",
    "cat_vars = data.loc[:, (data.dtypes==\"object\")]\n",
    "\n",
    "print(\"\\nContinuous columns: \\n\")\n",
    "pprint(list(cont_vars.columns), indent=4)\n",
    "print(\"\\n Categorical columns: \\n\")\n",
    "pprint(list(cat_vars.columns), indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outliers\n",
    "\n",
    "Outliers are data points that significantly differ from the majority of observations in a dataset and can distort statistical analysis or model performance. To identify and remove outliers, one common method is to use the Z-score, which measures how many standard deviations a data point is from the mean. Data points with a Z-score greater than 2 (or sometimes 3) standard deviations away from the mean are typically considered outliers. By applying this threshold, we can filter out values that fall outside the normal range of the data, ensuring that the remaining dataset is more representative and less influenced by extreme values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Missing</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>purchases</th>\n",
       "      <td>2937.000</td>\n",
       "      <td>2937.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>0.578</td>\n",
       "      <td>9.495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_spent</th>\n",
       "      <td>2937.000</td>\n",
       "      <td>2937.000</td>\n",
       "      <td>100.015</td>\n",
       "      <td>80.082</td>\n",
       "      <td>119.902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_visits</th>\n",
       "      <td>2937.000</td>\n",
       "      <td>2937.000</td>\n",
       "      <td>8.884</td>\n",
       "      <td>1.000</td>\n",
       "      <td>22.334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Count  Missing    Mean    Min     Max\n",
       "purchases  2937.000 2937.000   5.000  0.578   9.495\n",
       "time_spent 2937.000 2937.000 100.015 80.082 119.902\n",
       "n_visits   2937.000 2937.000   8.884  1.000  22.334"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_vars = cont_vars.apply(lambda x: x.clip(lower = (x.mean()-2*x.std()),\n",
    "                                             upper = (x.mean()+2*x.std())))\n",
    "outlier_summary = cont_vars.apply(describe_numeric_col).T\n",
    "outlier_summary.to_csv('./artifacts/outlier_summary.csv')\n",
    "outlier_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impute data\n",
    "\n",
    "In real-world datasets, missing data is a common occurrence due to various factors such as human error, incomplete data collection processes, or system failures. These gaps in the data can hinder analysis and lead to biased results if not properly addressed. Since many analytical and machine learning algorithms require complete data, handling missing values is an essential step in the data preprocessing phase.\n",
    "\n",
    "In the next code block, we will handle missing data by performing imputation. For numerical columns, we will replace missing values with the mean or median of the entire column, which provides a reasonable estimate based on the existing data. For categorical columns (object type), we will use the mode, or most frequent value, to fill in missing entries. This approach helps us maintain a complete dataset while ensuring that the imputed values align with the general distribution of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lead_id</th>\n",
       "      <th>lead_indicator</th>\n",
       "      <th>date_part</th>\n",
       "      <th>source</th>\n",
       "      <th>customer_group</th>\n",
       "      <th>onboarding</th>\n",
       "      <th>customer_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2024-01-06</td>\n",
       "      <td>signup</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>AAAEJOLSFX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AACEDUWABX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AAJURHRBIM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AAMFOUYNWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AAXKODEIPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2932</th>\n",
       "      <td>12328</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2933</th>\n",
       "      <td>12330</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2934</th>\n",
       "      <td>12334</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935</th>\n",
       "      <td>12337</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2936</th>\n",
       "      <td>12343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2937 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     lead_id lead_indicator   date_part  source customer_group onboarding  \\\n",
       "0          2          0.000  2024-01-06  signup              5       True   \n",
       "1         10            NaN         NaN     NaN            NaN        NaN   \n",
       "2         13            NaN         NaN     NaN            NaN        NaN   \n",
       "3         17            NaN         NaN     NaN            NaN        NaN   \n",
       "4         19            NaN         NaN     NaN            NaN        NaN   \n",
       "...      ...            ...         ...     ...            ...        ...   \n",
       "2932   12328            NaN         NaN     NaN            NaN        NaN   \n",
       "2933   12330            NaN         NaN     NaN            NaN        NaN   \n",
       "2934   12334            NaN         NaN     NaN            NaN        NaN   \n",
       "2935   12337            NaN         NaN     NaN            NaN        NaN   \n",
       "2936   12343            NaN         NaN     NaN            NaN        NaN   \n",
       "\n",
       "     customer_code  \n",
       "0       AAAEJOLSFX  \n",
       "1       AACEDUWABX  \n",
       "2       AAJURHRBIM  \n",
       "3       AAMFOUYNWS  \n",
       "4       AAXKODEIPG  \n",
       "...            ...  \n",
       "2932           NaN  \n",
       "2933           NaN  \n",
       "2934           NaN  \n",
       "2935           NaN  \n",
       "2936           NaN  \n",
       "\n",
       "[2937 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_missing_impute = cat_vars.mode(numeric_only=False, dropna=True)\n",
    "cat_missing_impute.to_csv(\"./artifacts/cat_missing_impute.csv\")\n",
    "cat_missing_impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Missing</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>purchases</th>\n",
       "      <td>2937.000</td>\n",
       "      <td>2937.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>0.578</td>\n",
       "      <td>9.495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_spent</th>\n",
       "      <td>2937.000</td>\n",
       "      <td>2937.000</td>\n",
       "      <td>100.015</td>\n",
       "      <td>80.082</td>\n",
       "      <td>119.902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_visits</th>\n",
       "      <td>2937.000</td>\n",
       "      <td>2937.000</td>\n",
       "      <td>8.884</td>\n",
       "      <td>1.000</td>\n",
       "      <td>22.334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Count  Missing    Mean    Min     Max\n",
       "purchases  2937.000 2937.000   5.000  0.578   9.495\n",
       "time_spent 2937.000 2937.000 100.015 80.082 119.902\n",
       "n_visits   2937.000 2937.000   8.884  1.000  22.334"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Continuous variables missing values\n",
    "cont_vars = cont_vars.apply(impute_missing_values)\n",
    "cont_vars.apply(describe_numeric_col).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lead_id</th>\n",
       "      <th>lead_indicator</th>\n",
       "      <th>date_part</th>\n",
       "      <th>source</th>\n",
       "      <th>customer_group</th>\n",
       "      <th>onboarding</th>\n",
       "      <th>customer_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2024-01-27</td>\n",
       "      <td>signup</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>STWPXVNOWA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2024-01-11</td>\n",
       "      <td>signup</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>JWLXPVANUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2024-01-22</td>\n",
       "      <td>signup</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>WNKCTHUHYI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2024-01-07</td>\n",
       "      <td>signup</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>INIQMTGGOO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2024-01-20</td>\n",
       "      <td>signup</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>SJGDAANOYJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12328</th>\n",
       "      <td>12328</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>signup</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>AYAVVZAMGV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12330</th>\n",
       "      <td>12330</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>signup</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>YFKCVZSAJF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12334</th>\n",
       "      <td>12334</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2024-01-21</td>\n",
       "      <td>signup</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>ROVGLTVJNL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12337</th>\n",
       "      <td>12337</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2024-01-03</td>\n",
       "      <td>signup</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>BGQNNVRTDH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12343</th>\n",
       "      <td>12343</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2024-01-29</td>\n",
       "      <td>signup</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>UNUSNTTYXR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2937 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       lead_id  lead_indicator   date_part  source  customer_group  \\\n",
       "2            2           1.000  2024-01-27  signup               5   \n",
       "10          10           0.000  2024-01-11  signup               4   \n",
       "13          13           0.000  2024-01-22  signup               6   \n",
       "17          17           1.000  2024-01-07  signup               8   \n",
       "19          19           0.000  2024-01-20  signup               9   \n",
       "...        ...             ...         ...     ...             ...   \n",
       "12328    12328           1.000  2024-01-01  signup               5   \n",
       "12330    12330           1.000  2024-01-14  signup               4   \n",
       "12334    12334           0.000  2024-01-21  signup               5   \n",
       "12337    12337           1.000  2024-01-03  signup               6   \n",
       "12343    12343           1.000  2024-01-29  signup               8   \n",
       "\n",
       "       onboarding customer_code  \n",
       "2           False    STWPXVNOWA  \n",
       "10           True    JWLXPVANUM  \n",
       "13           True    WNKCTHUHYI  \n",
       "17          False    INIQMTGGOO  \n",
       "19           True    SJGDAANOYJ  \n",
       "...           ...           ...  \n",
       "12328        True    AYAVVZAMGV  \n",
       "12330        True    YFKCVZSAJF  \n",
       "12334        True    ROVGLTVJNL  \n",
       "12337        True    BGQNNVRTDH  \n",
       "12343        True    UNUSNTTYXR  \n",
       "\n",
       "[2937 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_vars.loc[cat_vars['customer_code'].isna(),'customer_code'] = 'None'\n",
    "cat_vars = cat_vars.apply(impute_missing_values)\n",
    "cat_vars.apply(lambda x: pd.Series([x.count(), x.isnull().sum()], index = ['Count', 'Missing'])).T\n",
    "cat_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data standardisation\n",
    "\n",
    "Standardization, or scaling, becomes necessary when continuous independent variables are measured on different scales, as this can lead to unequal contributions to the analysis. The objective is to rescale these variables so they have comparable ranges and/or variances, ensuring a more balanced influence in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved scaler in artifacts\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>purchases</th>\n",
       "      <th>time_spent</th>\n",
       "      <th>n_visits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.272</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.832</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.608</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.496</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.272</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2932</th>\n",
       "      <td>0.159</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2933</th>\n",
       "      <td>0.608</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2934</th>\n",
       "      <td>0.047</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2936</th>\n",
       "      <td>0.832</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2937 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      purchases  time_spent  n_visits\n",
       "0         0.272       0.512     0.703\n",
       "1         0.832       0.648     0.141\n",
       "2         0.608       0.167     0.187\n",
       "3         0.496       0.675     0.328\n",
       "4         0.272       0.366     0.891\n",
       "...         ...         ...       ...\n",
       "2932      0.159       0.475     0.609\n",
       "2933      0.608       0.535     0.797\n",
       "2934      0.047       0.346     0.000\n",
       "2935      0.000       0.759     0.797\n",
       "2936      0.832       0.644     0.797\n",
       "\n",
       "[2937 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "\n",
    "scaler_path = \"./artifacts/scaler.pkl\"\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(cont_vars)\n",
    "\n",
    "joblib.dump(value=scaler, filename=scaler_path)\n",
    "print(\"Saved scaler in artifacts\")\n",
    "\n",
    "cont_vars = pd.DataFrame(scaler.transform(cont_vars), columns=cont_vars.columns)\n",
    "cont_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleansed and combined.\n",
      "Rows: 2937\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lead_id</th>\n",
       "      <th>lead_indicator</th>\n",
       "      <th>date_part</th>\n",
       "      <th>source</th>\n",
       "      <th>customer_group</th>\n",
       "      <th>onboarding</th>\n",
       "      <th>customer_code</th>\n",
       "      <th>purchases</th>\n",
       "      <th>time_spent</th>\n",
       "      <th>n_visits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2024-01-27</td>\n",
       "      <td>signup</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>STWPXVNOWA</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2024-01-11</td>\n",
       "      <td>signup</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>JWLXPVANUM</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2024-01-22</td>\n",
       "      <td>signup</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>WNKCTHUHYI</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2024-01-07</td>\n",
       "      <td>signup</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>INIQMTGGOO</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2024-01-20</td>\n",
       "      <td>signup</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>SJGDAANOYJ</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2932</th>\n",
       "      <td>12328</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>signup</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>AYAVVZAMGV</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2933</th>\n",
       "      <td>12330</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>signup</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>YFKCVZSAJF</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2934</th>\n",
       "      <td>12334</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2024-01-21</td>\n",
       "      <td>signup</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>ROVGLTVJNL</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935</th>\n",
       "      <td>12337</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2024-01-03</td>\n",
       "      <td>signup</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>BGQNNVRTDH</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2936</th>\n",
       "      <td>12343</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2024-01-29</td>\n",
       "      <td>signup</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>UNUSNTTYXR</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2937 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      lead_id  lead_indicator   date_part  source  customer_group  onboarding  \\\n",
       "0           2           1.000  2024-01-27  signup               5       False   \n",
       "1          10           0.000  2024-01-11  signup               4        True   \n",
       "2          13           0.000  2024-01-22  signup               6        True   \n",
       "3          17           1.000  2024-01-07  signup               8       False   \n",
       "4          19           0.000  2024-01-20  signup               9        True   \n",
       "...       ...             ...         ...     ...             ...         ...   \n",
       "2932    12328           1.000  2024-01-01  signup               5        True   \n",
       "2933    12330           1.000  2024-01-14  signup               4        True   \n",
       "2934    12334           0.000  2024-01-21  signup               5        True   \n",
       "2935    12337           1.000  2024-01-03  signup               6        True   \n",
       "2936    12343           1.000  2024-01-29  signup               8        True   \n",
       "\n",
       "     customer_code  purchases  time_spent  n_visits  \n",
       "0       STWPXVNOWA      0.272       0.512     0.703  \n",
       "1       JWLXPVANUM      0.832       0.648     0.141  \n",
       "2       WNKCTHUHYI      0.608       0.167     0.187  \n",
       "3       INIQMTGGOO      0.496       0.675     0.328  \n",
       "4       SJGDAANOYJ      0.272       0.366     0.891  \n",
       "...            ...        ...         ...       ...  \n",
       "2932    AYAVVZAMGV      0.159       0.475     0.609  \n",
       "2933    YFKCVZSAJF      0.608       0.535     0.797  \n",
       "2934    ROVGLTVJNL      0.047       0.346     0.000  \n",
       "2935    BGQNNVRTDH      0.000       0.759     0.797  \n",
       "2936    UNUSNTTYXR      0.832       0.644     0.797  \n",
       "\n",
       "[2937 rows x 10 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_vars = cont_vars.reset_index(drop=True)\n",
    "cat_vars = cat_vars.reset_index(drop=True)\n",
    "data = pd.concat([cat_vars, cont_vars], axis=1)\n",
    "print(f\"Data cleansed and combined.\\nRows: {len(data)}\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data drift artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data_columns = list(data.columns)\n",
    "with open('./artifacts/columns_drift.json','w+') as f:           \n",
    "    json.dump(data_columns,f)\n",
    "    \n",
    "data.to_csv('./artifacts/training_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binning object columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['lead_id', 'lead_indicator', 'date_part', 'source', 'customer_group',\n",
       "       'onboarding', 'customer_code', 'purchases', 'time_spent', 'n_visits'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['bin_source'] = data['source']\n",
    "values_list = ['li', 'organic','signup','fb']\n",
    "data.loc[~data['source'].isin(values_list),'bin_source'] = 'Others'\n",
    "mapping = {'li' : 'socials', \n",
    "           'fb' : 'socials', \n",
    "           'organic': 'group1', \n",
    "           'signup': 'group1'\n",
    "           }\n",
    "\n",
    "data['bin_source'] = data['source'].map(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save gold medallion dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.sql(f\"drop table if exists train_gold\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_gold = spark.createDataFrame(data)\n",
    "# data_gold.write.saveAsTable('train_gold')\n",
    "# dbutils.notebook.exit(('training_golden_data',most_recent_date))\n",
    "\n",
    "data.to_csv('./artifacts/train_data_gold.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL TRAINING\n",
    "\n",
    "Training the model uses a training dataset for training an ML algorithm. It has sample output data and the matching input data that affects the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# Constants used:\n",
    "current_date = datetime.datetime.now().strftime(\"%Y_%B_%d\")\n",
    "data_gold_path = \"./artifacts/train_data_gold.csv\"\n",
    "data_version = \"00000\"\n",
    "experiment_name = current_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create paths\n",
    "\n",
    "Maybe the artifacts path has not been created during data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "os.makedirs(\"artifacts\", exist_ok=True)\n",
    "os.makedirs(\"mlruns\", exist_ok=True)\n",
    "os.makedirs(\"mlruns/.trash\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///c:/Users/Frederik/MLOps_2025_Project/notebooks/mlruns/963873149639731999', creation_time=1763375318633, experiment_id='963873149639731999', last_update_time=1763375318633, lifecycle_stage='active', name='2025_November_17', tags={}>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions\n",
    "\n",
    "* *create_dummies*: Create one-hot encoding columns in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dummy_cols(df, col):\n",
    "    df_dummies = pd.get_dummies(df[col], prefix=col, drop_first=True)\n",
    "    new_df = pd.concat([df, df_dummies], axis=1)\n",
    "    new_df = new_df.drop(col, axis=1)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load training data\n",
    "We use the training data we cleaned earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data length: 2937\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lead_id</th>\n",
       "      <th>lead_indicator</th>\n",
       "      <th>date_part</th>\n",
       "      <th>source</th>\n",
       "      <th>customer_group</th>\n",
       "      <th>onboarding</th>\n",
       "      <th>customer_code</th>\n",
       "      <th>purchases</th>\n",
       "      <th>time_spent</th>\n",
       "      <th>n_visits</th>\n",
       "      <th>bin_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2024-01-27</td>\n",
       "      <td>signup</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>STWPXVNOWA</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.703</td>\n",
       "      <td>group1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2024-01-11</td>\n",
       "      <td>signup</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>JWLXPVANUM</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.141</td>\n",
       "      <td>group1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2024-01-22</td>\n",
       "      <td>signup</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>WNKCTHUHYI</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.187</td>\n",
       "      <td>group1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2024-01-07</td>\n",
       "      <td>signup</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>INIQMTGGOO</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.328</td>\n",
       "      <td>group1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2024-01-20</td>\n",
       "      <td>signup</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>SJGDAANOYJ</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.891</td>\n",
       "      <td>group1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lead_id  lead_indicator   date_part  source  customer_group  onboarding  \\\n",
       "0        2           1.000  2024-01-27  signup               5       False   \n",
       "1       10           0.000  2024-01-11  signup               4        True   \n",
       "2       13           0.000  2024-01-22  signup               6        True   \n",
       "3       17           1.000  2024-01-07  signup               8       False   \n",
       "4       19           0.000  2024-01-20  signup               9        True   \n",
       "\n",
       "  customer_code  purchases  time_spent  n_visits bin_source  \n",
       "0    STWPXVNOWA      0.272       0.512     0.703     group1  \n",
       "1    JWLXPVANUM      0.832       0.648     0.141     group1  \n",
       "2    WNKCTHUHYI      0.608       0.167     0.187     group1  \n",
       "3    INIQMTGGOO      0.496       0.675     0.328     group1  \n",
       "4    SJGDAANOYJ      0.272       0.366     0.891     group1  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(data_gold_path)\n",
    "print(f\"Training data length: {len(data)}\")\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data type split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop([\"lead_id\", \"customer_code\", \"date_part\"], axis=1)\n",
    "\n",
    "cat_cols = [\"customer_group\", \"onboarding\", \"bin_source\", \"source\"]\n",
    "cat_vars = data[cat_cols]\n",
    "\n",
    "other_vars = data.drop(cat_cols, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy variable for categorical vars\n",
    "\n",
    "1. Create one-hot encoded cols for cat vars\n",
    "2. Change to floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed column lead_indicator to float\n",
      "Changed column purchases to float\n",
      "Changed column time_spent to float\n",
      "Changed column n_visits to float\n",
      "Changed column customer_group_2 to float\n",
      "Changed column customer_group_3 to float\n",
      "Changed column customer_group_4 to float\n",
      "Changed column customer_group_5 to float\n",
      "Changed column customer_group_6 to float\n",
      "Changed column customer_group_7 to float\n",
      "Changed column customer_group_8 to float\n",
      "Changed column customer_group_9 to float\n",
      "Changed column onboarding_True to float\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "for col in cat_vars:\n",
    "    cat_vars[col] = cat_vars[col].astype(\"category\")\n",
    "    cat_vars = create_dummy_cols(cat_vars, col)\n",
    "\n",
    "data = pd.concat([other_vars, cat_vars], axis=1)\n",
    "\n",
    "for col in data:\n",
    "    data[col] = data[col].astype(\"float64\")\n",
    "    print(f\"Changed column {col} to float\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[\"lead_indicator\"]\n",
    "X = data.drop([\"lead_indicator\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "335    1.000\n",
       "499    0.000\n",
       "2850   1.000\n",
       "2142   0.000\n",
       "1019   0.000\n",
       "        ... \n",
       "1378   0.000\n",
       "2771   0.000\n",
       "28     0.000\n",
       "1410   1.000\n",
       "2488   1.000\n",
       "Name: lead_indicator, Length: 2496, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=42, test_size=0.15, stratify=y\n",
    ")\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training\n",
    "\n",
    "This stage involves training the ML algorithm by providing it with datasets, where the learning process takes place. Consistent training can significantly enhance the model's prediction accuracy. It's essential to initialize the model's weights randomly so the algorithm can effectively learn to adjust them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=10,\n",
       "                   estimator=XGBRFClassifier(base_score=None, booster=None,\n",
       "                                             callbacks=None,\n",
       "                                             colsample_bylevel=None,\n",
       "                                             colsample_bytree=None, device=None,\n",
       "                                             early_stopping_rounds=None,\n",
       "                                             enable_categorical=False,\n",
       "                                             eval_metric=None,\n",
       "                                             feature_types=None,\n",
       "                                             feature_weights=None, gamma=None,\n",
       "                                             grow_policy=None,\n",
       "                                             importance_type=None,\n",
       "                                             interaction_constraints=None,\n",
       "                                             max_bin=Non...\n",
       "                                        &#x27;max_depth&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x000001F9FD50C450&gt;,\n",
       "                                        &#x27;min_split_loss&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000001F9FD243090&gt;,\n",
       "                                        &#x27;objective&#x27;: [&#x27;reg:squarederror&#x27;,\n",
       "                                                      &#x27;binary:logistic&#x27;,\n",
       "                                                      &#x27;reg:logistic&#x27;],\n",
       "                                        &#x27;subsample&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000001F9FD242ED0&gt;},\n",
       "                   verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=10,\n",
       "                   estimator=XGBRFClassifier(base_score=None, booster=None,\n",
       "                                             callbacks=None,\n",
       "                                             colsample_bylevel=None,\n",
       "                                             colsample_bytree=None, device=None,\n",
       "                                             early_stopping_rounds=None,\n",
       "                                             enable_categorical=False,\n",
       "                                             eval_metric=None,\n",
       "                                             feature_types=None,\n",
       "                                             feature_weights=None, gamma=None,\n",
       "                                             grow_policy=None,\n",
       "                                             importance_type=None,\n",
       "                                             interaction_constraints=None,\n",
       "                                             max_bin=Non...\n",
       "                                        &#x27;max_depth&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x000001F9FD50C450&gt;,\n",
       "                                        &#x27;min_split_loss&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000001F9FD243090&gt;,\n",
       "                                        &#x27;objective&#x27;: [&#x27;reg:squarederror&#x27;,\n",
       "                                                      &#x27;binary:logistic&#x27;,\n",
       "                                                      &#x27;reg:logistic&#x27;],\n",
       "                                        &#x27;subsample&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000001F9FD242ED0&gt;},\n",
       "                   verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRFClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBRFClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                colsample_bylevel=None, colsample_bytree=None, device=None,\n",
       "                early_stopping_rounds=None, enable_categorical=False,\n",
       "                eval_metric=None, feature_types=None, feature_weights=None,\n",
       "                gamma=None, grow_policy=None, importance_type=None,\n",
       "                interaction_constraints=None, max_bin=None,\n",
       "                max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "                min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "                multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "                num_parallel_tree=None, objective=&#x27;binary:logistic&#x27;,\n",
       "                random_state=42, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRFClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBRFClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                colsample_bylevel=None, colsample_bytree=None, device=None,\n",
       "                early_stopping_rounds=None, enable_categorical=False,\n",
       "                eval_metric=None, feature_types=None, feature_weights=None,\n",
       "                gamma=None, grow_policy=None, importance_type=None,\n",
       "                interaction_constraints=None, max_bin=None,\n",
       "                max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "                min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "                multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "                num_parallel_tree=None, objective=&#x27;binary:logistic&#x27;,\n",
       "                random_state=42, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=10,\n",
       "                   estimator=XGBRFClassifier(base_score=None, booster=None,\n",
       "                                             callbacks=None,\n",
       "                                             colsample_bylevel=None,\n",
       "                                             colsample_bytree=None, device=None,\n",
       "                                             early_stopping_rounds=None,\n",
       "                                             enable_categorical=False,\n",
       "                                             eval_metric=None,\n",
       "                                             feature_types=None,\n",
       "                                             feature_weights=None, gamma=None,\n",
       "                                             grow_policy=None,\n",
       "                                             importance_type=None,\n",
       "                                             interaction_constraints=None,\n",
       "                                             max_bin=Non...\n",
       "                                        'max_depth': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x000001F9FD50C450>,\n",
       "                                        'min_split_loss': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000001F9FD243090>,\n",
       "                                        'objective': ['reg:squarederror',\n",
       "                                                      'binary:logistic',\n",
       "                                                      'reg:logistic'],\n",
       "                                        'subsample': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000001F9FD242ED0>},\n",
       "                   verbose=3)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRFClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "from scipy.stats import randint\n",
    "\n",
    "model = XGBRFClassifier(random_state=42)\n",
    "params = {\n",
    "    \"learning_rate\": uniform(1e-2, 3e-1),\n",
    "    \"min_split_loss\": uniform(0, 10),\n",
    "    \"max_depth\": randint(3, 10),\n",
    "    \"subsample\": uniform(0, 1),\n",
    "    \"objective\": [\"reg:squarederror\", \"binary:logistic\", \"reg:logistic\"],\n",
    "    \"eval_metric\": [\"aucpr\", \"error\"]\n",
    "}\n",
    "\n",
    "model_grid = RandomizedSearchCV(model, param_distributions=params, n_jobs=-1, verbose=3, n_iter=10, cv=10)\n",
    "\n",
    "model_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best xgboost params\n",
      "{'eval_metric': 'aucpr',\n",
      " 'learning_rate': 0.22972644340833354,\n",
      " 'max_depth': 8,\n",
      " 'min_split_loss': 6.991484728516927,\n",
      " 'objective': 'reg:logistic',\n",
      " 'subsample': 0.3694759106232305}\n",
      "Accuracy train 0.8096955128205128\n",
      "Accuracy test 0.7755102040816326\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "best_model_xgboost_params = model_grid.best_params_\n",
    "print(\"Best xgboost params\")\n",
    "pprint(best_model_xgboost_params)\n",
    "\n",
    "y_pred_train = model_grid.predict(X_train)\n",
    "y_pred_test = model_grid.predict(X_test)\n",
    "print(\"Accuracy train\", accuracy_score(y_pred_train, y_train ))\n",
    "print(\"Accuracy test\", accuracy_score(y_pred_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost performance overview\n",
    "* Confusion matrix\n",
    "* Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test actual/predicted\n",
      "\n",
      "Predicted    0    1  All\n",
      "Actual                  \n",
      "0.000      209   26  235\n",
      "1.000       73  133  206\n",
      " All       282  159  441 \n",
      "\n",
      "Classification report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.89      0.81       235\n",
      "         1.0       0.84      0.65      0.73       206\n",
      "\n",
      "    accuracy                           0.78       441\n",
      "   macro avg       0.79      0.77      0.77       441\n",
      "weighted avg       0.79      0.78      0.77       441\n",
      " \n",
      "\n",
      "Train actual/predicted\n",
      "\n",
      "Predicted     0     1   All\n",
      "Actual                     \n",
      "0.000      1146   181  1327\n",
      "1.000       294   875  1169\n",
      " All       1440  1056  2496 \n",
      "\n",
      "Classification report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.86      0.83      1327\n",
      "         1.0       0.83      0.75      0.79      1169\n",
      "\n",
      "    accuracy                           0.81      2496\n",
      "   macro avg       0.81      0.81      0.81      2496\n",
      "weighted avg       0.81      0.81      0.81      2496\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_test)\n",
    "print(\"Test actual/predicted\\n\")\n",
    "print(pd.crosstab(y_test, y_pred_test, rownames=['Actual'], colnames=['Predicted'], margins=True),'\\n')\n",
    "print(\"Classification report\\n\")\n",
    "print(classification_report(y_test, y_pred_test),'\\n')\n",
    "\n",
    "conf_matrix = confusion_matrix(y_train, y_pred_train)\n",
    "print(\"Train actual/predicted\\n\")\n",
    "print(pd.crosstab(y_train, y_pred_train, rownames=['Actual'], colnames=['Predicted'], margins=True),'\\n')\n",
    "print(\"Classification report\\n\")\n",
    "print(classification_report(y_train, y_pred_train),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save best XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_model = model_grid.best_estimator_\n",
    "xgboost_model_path = \"./artifacts/lead_model_xgboost.json\"\n",
    "xgboost_model.save_model(xgboost_model_path)\n",
    "\n",
    "model_results = {\n",
    "    xgboost_model_path: classification_report(y_train, y_pred_train, output_dict=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKLearn logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 17\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, context, model_input):\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpredict_proba(model_input)[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 17\u001b[0m mlflow\u001b[38;5;241m.\u001b[39msklearn\u001b[38;5;241m.\u001b[39mautolog(log_input_examples\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, log_models\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     18\u001b[0m experiment_id \u001b[38;5;241m=\u001b[39m mlflow\u001b[38;5;241m.\u001b[39mget_experiment_by_name(experiment_name)\u001b[38;5;241m.\u001b[39mexperiment_id\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mlflow\u001b[38;5;241m.\u001b[39mstart_run(experiment_id\u001b[38;5;241m=\u001b[39mexperiment_id) \u001b[38;5;28;01mas\u001b[39;00m run:\n",
      "File \u001b[1;32mc:\\Users\\Frederik\\anaconda3\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\__init__.py:432\u001b[0m, in \u001b[0;36mautologging_integration.<locals>.wrapper.<locals>.autolog\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m set_mlflow_events_and_warnings_behavior_globally(\n\u001b[0;32m    414\u001b[0m     \u001b[38;5;66;03m# MLflow warnings emitted during autologging setup / enablement are likely\u001b[39;00m\n\u001b[0;32m    415\u001b[0m     \u001b[38;5;66;03m# actionable and relevant to the user, so they should be emitted as normal\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    428\u001b[0m     disable_warnings\u001b[38;5;241m=\u001b[39mis_silent_mode,\n\u001b[0;32m    429\u001b[0m ):\n\u001b[0;32m    430\u001b[0m     _check_and_log_warning_for_unsupported_package_versions(name)\n\u001b[1;32m--> 432\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _autolog(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Frederik\\anaconda3\\Lib\\site-packages\\mlflow\\sklearn\\__init__.py:1283\u001b[0m, in \u001b[0;36mautolog\u001b[1;34m(log_input_examples, log_model_signatures, log_models, log_datasets, disable, exclusive, disable_for_unsupported_versions, silent, max_tuning_runs, log_post_training_metrics, serialization_format, registered_model_name, pos_label, extra_tags)\u001b[0m\n\u001b[0;32m    997\u001b[0m \u001b[38;5;129m@autologging_integration\u001b[39m(FLAVOR_NAME)\n\u001b[0;32m    998\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mautolog\u001b[39m(\n\u001b[0;32m    999\u001b[0m     log_input_examples\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     extra_tags\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1013\u001b[0m ):\n\u001b[0;32m   1014\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1015\u001b[0m \u001b[38;5;124;03m    Enables (or disables) and configures autologging for scikit-learn estimators.\u001b[39;00m\n\u001b[0;32m   1016\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1281\u001b[0m \u001b[38;5;124;03m        extra_tags: A dictionary of extra tags to set on each managed run created by autologging.\u001b[39;00m\n\u001b[0;32m   1282\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1283\u001b[0m     _autolog(\n\u001b[0;32m   1284\u001b[0m         flavor_name\u001b[38;5;241m=\u001b[39mFLAVOR_NAME,\n\u001b[0;32m   1285\u001b[0m         log_input_examples\u001b[38;5;241m=\u001b[39mlog_input_examples,\n\u001b[0;32m   1286\u001b[0m         log_model_signatures\u001b[38;5;241m=\u001b[39mlog_model_signatures,\n\u001b[0;32m   1287\u001b[0m         log_models\u001b[38;5;241m=\u001b[39mlog_models,\n\u001b[0;32m   1288\u001b[0m         log_datasets\u001b[38;5;241m=\u001b[39mlog_datasets,\n\u001b[0;32m   1289\u001b[0m         disable\u001b[38;5;241m=\u001b[39mdisable,\n\u001b[0;32m   1290\u001b[0m         exclusive\u001b[38;5;241m=\u001b[39mexclusive,\n\u001b[0;32m   1291\u001b[0m         disable_for_unsupported_versions\u001b[38;5;241m=\u001b[39mdisable_for_unsupported_versions,\n\u001b[0;32m   1292\u001b[0m         silent\u001b[38;5;241m=\u001b[39msilent,\n\u001b[0;32m   1293\u001b[0m         max_tuning_runs\u001b[38;5;241m=\u001b[39mmax_tuning_runs,\n\u001b[0;32m   1294\u001b[0m         log_post_training_metrics\u001b[38;5;241m=\u001b[39mlog_post_training_metrics,\n\u001b[0;32m   1295\u001b[0m         serialization_format\u001b[38;5;241m=\u001b[39mserialization_format,\n\u001b[0;32m   1296\u001b[0m         pos_label\u001b[38;5;241m=\u001b[39mpos_label,\n\u001b[0;32m   1297\u001b[0m         extra_tags\u001b[38;5;241m=\u001b[39mextra_tags,\n\u001b[0;32m   1298\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Frederik\\anaconda3\\Lib\\site-packages\\mlflow\\sklearn\\__init__.py:1845\u001b[0m, in \u001b[0;36m_autolog\u001b[1;34m(flavor_name, log_input_examples, log_model_signatures, log_models, log_datasets, disable, exclusive, disable_for_unsupported_versions, silent, max_tuning_runs, log_post_training_metrics, serialization_format, pos_label, extra_tags)\u001b[0m\n\u001b[0;32m   1843\u001b[0m     allow_children_patch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1844\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1845\u001b[0m     estimators_to_patch \u001b[38;5;241m=\u001b[39m _gen_estimators_to_patch()\n\u001b[0;32m   1846\u001b[0m     patched_fit_impl \u001b[38;5;241m=\u001b[39m fit_mlflow\n\u001b[0;32m   1847\u001b[0m     allow_children_patch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Frederik\\anaconda3\\Lib\\site-packages\\mlflow\\sklearn\\__init__.py:100\u001b[0m, in \u001b[0;36m_gen_estimators_to_patch\u001b[1;34m()\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_gen_estimators_to_patch\u001b[39m():\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmlflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     96\u001b[0m         _all_estimators,\n\u001b[0;32m     97\u001b[0m         _get_meta_estimators_for_autologging,\n\u001b[0;32m     98\u001b[0m     )\n\u001b[1;32m--> 100\u001b[0m     _, estimators_to_patch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m_all_estimators())\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;66;03m# Ensure that relevant meta estimators (e.g. GridSearchCV, Pipeline) are selected\u001b[39;00m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;66;03m# for patching if they are not already included in the output of `all_estimators()`\u001b[39;00m\n\u001b[0;32m    103\u001b[0m     estimators_to_patch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(estimators_to_patch)\u001b[38;5;241m.\u001b[39munion(\n\u001b[0;32m    104\u001b[0m         \u001b[38;5;28mset\u001b[39m(_get_meta_estimators_for_autologging())\n\u001b[0;32m    105\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Frederik\\anaconda3\\Lib\\site-packages\\mlflow\\sklearn\\utils.py:876\u001b[0m, in \u001b[0;36m_all_estimators\u001b[1;34m()\u001b[0m\n\u001b[0;32m    873\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    874\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m all_estimators\n\u001b[1;32m--> 876\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m all_estimators()\n\u001b[0;32m    877\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m    878\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _backported_all_estimators()\n",
      "File \u001b[1;32mc:\\Users\\Frederik\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\discovery.py:49\u001b[0m, in \u001b[0;36mall_estimators\u001b[1;34m(type_filter)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     42\u001b[0m     BaseEstimator,\n\u001b[0;32m     43\u001b[0m     ClassifierMixin,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     46\u001b[0m     TransformerMixin,\n\u001b[0;32m     47\u001b[0m )\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IS_PYPY\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_testing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ignore_warnings\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_abstract\u001b[39m(c):\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(c, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__abstractmethods__\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n",
      "File \u001b[1;32mc:\\Users\\Frederik\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_testing.py:395\u001b[0m\n\u001b[0;32m    392\u001b[0m skip_if_32bit \u001b[38;5;241m=\u001b[39m pytest\u001b[38;5;241m.\u001b[39mmark\u001b[38;5;241m.\u001b[39mskipif(_IS_32BIT, reason\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipped on 32bit platforms\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    393\u001b[0m fails_if_pypy \u001b[38;5;241m=\u001b[39m pytest\u001b[38;5;241m.\u001b[39mmark\u001b[38;5;241m.\u001b[39mxfail(IS_PYPY, reason\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot compatible with PyPy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    394\u001b[0m fails_if_unstable_openblas \u001b[38;5;241m=\u001b[39m pytest\u001b[38;5;241m.\u001b[39mmark\u001b[38;5;241m.\u001b[39mxfail(\n\u001b[1;32m--> 395\u001b[0m     _in_unstable_openblas_configuration(),\n\u001b[0;32m    396\u001b[0m     reason\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpenBLAS is unstable for this configuration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    397\u001b[0m )\n\u001b[0;32m    398\u001b[0m skip_if_no_parallel \u001b[38;5;241m=\u001b[39m pytest\u001b[38;5;241m.\u001b[39mmark\u001b[38;5;241m.\u001b[39mskipif(\n\u001b[0;32m    399\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m joblib\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39mmp, reason\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjoblib is in serial mode\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    400\u001b[0m )\n\u001b[0;32m    401\u001b[0m skip_if_array_api_compat_not_configured \u001b[38;5;241m=\u001b[39m pytest\u001b[38;5;241m.\u001b[39mmark\u001b[38;5;241m.\u001b[39mskipif(\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m ARRAY_API_COMPAT_FUNCTIONAL,\n\u001b[0;32m    403\u001b[0m     reason\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires array_api_compat installed and a new enough version of NumPy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    404\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Frederik\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\__init__.py:89\u001b[0m, in \u001b[0;36m_in_unstable_openblas_configuration\u001b[1;34m()\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m---> 89\u001b[0m modules_info \u001b[38;5;241m=\u001b[39m threadpool_info()\n\u001b[0;32m     91\u001b[0m open_blas_used \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m(info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minternal_api\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenblas\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m info \u001b[38;5;129;01min\u001b[39;00m modules_info)\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m open_blas_used:\n",
      "File \u001b[1;32mc:\\Users\\Frederik\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\fixes.py:83\u001b[0m, in \u001b[0;36mthreadpool_info\u001b[1;34m()\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m controller\u001b[38;5;241m.\u001b[39minfo()\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 83\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m threadpoolctl\u001b[38;5;241m.\u001b[39mthreadpool_info()\n",
      "File \u001b[1;32mc:\\Users\\Frederik\\anaconda3\\Lib\\site-packages\\threadpoolctl.py:124\u001b[0m, in \u001b[0;36mthreadpool_info\u001b[1;34m()\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;129m@_format_docstring\u001b[39m(USER_APIS\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(_ALL_USER_APIS),\n\u001b[0;32m    108\u001b[0m                    INTERNAL_APIS\u001b[38;5;241m=\u001b[39m_ALL_INTERNAL_APIS)\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mthreadpool_info\u001b[39m():\n\u001b[0;32m    110\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the maximal number of threads for each detected library.\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \n\u001b[0;32m    112\u001b[0m \u001b[38;5;124;03m    Return a list with all the supported modules that have been found. Each\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;124;03m    In addition, each module may contain internal_api specific entries.\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _ThreadpoolInfo(user_api\u001b[38;5;241m=\u001b[39m_ALL_USER_APIS)\u001b[38;5;241m.\u001b[39mtodicts()\n",
      "File \u001b[1;32mc:\\Users\\Frederik\\anaconda3\\Lib\\site-packages\\threadpoolctl.py:340\u001b[0m, in \u001b[0;36m_ThreadpoolInfo.__init__\u001b[1;34m(self, user_api, prefixes, modules)\u001b[0m\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_api \u001b[38;5;241m=\u001b[39m [] \u001b[38;5;28;01mif\u001b[39;00m user_api \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m user_api\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodules \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 340\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_modules()\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_if_incompatible_openmp()\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Frederik\\anaconda3\\Lib\\site-packages\\threadpoolctl.py:373\u001b[0m, in \u001b[0;36m_ThreadpoolInfo._load_modules\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    371\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find_modules_with_dyld()\n\u001b[0;32m    372\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mplatform \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwin32\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 373\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find_modules_with_enum_process_module_ex()\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    375\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find_modules_with_dl_iterate_phdr()\n",
      "File \u001b[1;32mc:\\Users\\Frederik\\anaconda3\\Lib\\site-packages\\threadpoolctl.py:485\u001b[0m, in \u001b[0;36m_ThreadpoolInfo._find_modules_with_enum_process_module_ex\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    482\u001b[0m         filepath \u001b[38;5;241m=\u001b[39m buf\u001b[38;5;241m.\u001b[39mvalue\n\u001b[0;32m    484\u001b[0m         \u001b[38;5;66;03m# Store the module if it is supported and selected\u001b[39;00m\n\u001b[1;32m--> 485\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_module_from_path(filepath)\n\u001b[0;32m    486\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    487\u001b[0m     kernel_32\u001b[38;5;241m.\u001b[39mCloseHandle(h_process)\n",
      "File \u001b[1;32mc:\\Users\\Frederik\\anaconda3\\Lib\\site-packages\\threadpoolctl.py:515\u001b[0m, in \u001b[0;36m_ThreadpoolInfo._make_module_from_path\u001b[1;34m(self, filepath)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prefix \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprefixes \u001b[38;5;129;01mor\u001b[39;00m user_api \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_api:\n\u001b[0;32m    514\u001b[0m     module_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mglobals\u001b[39m()[module_class]\n\u001b[1;32m--> 515\u001b[0m     module \u001b[38;5;241m=\u001b[39m module_class(filepath, prefix, user_api, internal_api)\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodules\u001b[38;5;241m.\u001b[39mappend(module)\n",
      "File \u001b[1;32mc:\\Users\\Frederik\\anaconda3\\Lib\\site-packages\\threadpoolctl.py:606\u001b[0m, in \u001b[0;36m_Module.__init__\u001b[1;34m(self, filepath, prefix, user_api, internal_api)\u001b[0m\n\u001b[0;32m    604\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minternal_api \u001b[38;5;241m=\u001b[39m internal_api\n\u001b[0;32m    605\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dynlib \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mCDLL(filepath, mode\u001b[38;5;241m=\u001b[39m_RTLD_NOLOAD)\n\u001b[1;32m--> 606\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mversion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_version()\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_num_threads()\n\u001b[0;32m    608\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_extra_info()\n",
      "File \u001b[1;32mc:\\Users\\Frederik\\anaconda3\\Lib\\site-packages\\threadpoolctl.py:646\u001b[0m, in \u001b[0;36m_OpenBLASModule.get_version\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    643\u001b[0m get_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dynlib, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenblas_get_config\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    644\u001b[0m                      \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    645\u001b[0m get_config\u001b[38;5;241m.\u001b[39mrestype \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mc_char_p\n\u001b[1;32m--> 646\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\u001b[38;5;241m.\u001b[39msplit()\n\u001b[0;32m    647\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpenBLAS\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m config[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "import mlflow.pyfunc\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import os\n",
    "from sklearn.metrics import cohen_kappa_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "class lr_wrapper(mlflow.pyfunc.PythonModel):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    \n",
    "    def predict(self, context, model_input):\n",
    "        return self.model.predict_proba(model_input)[:, 1]\n",
    "\n",
    "\n",
    "mlflow.sklearn.autolog(log_input_examples=True, log_models=False)\n",
    "experiment_id = mlflow.get_experiment_by_name(experiment_name).experiment_id\n",
    "\n",
    "with mlflow.start_run(experiment_id=experiment_id) as run:\n",
    "    model = LogisticRegression()\n",
    "    lr_model_path = \"./artifacts/lead_model_lr.pkl\"\n",
    "\n",
    "    params = {\n",
    "              'solver': [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"],\n",
    "              'penalty':  [\"none\", \"l1\", \"l2\", \"elasticnet\"],\n",
    "              'C' : [100, 10, 1.0, 0.1, 0.01]\n",
    "    }\n",
    "    model_grid = RandomizedSearchCV(model, param_distributions= params, verbose=3, n_iter=10, cv=3)\n",
    "    model_grid.fit(X_train, y_train)\n",
    "\n",
    "    best_model = model_grid.best_estimator_\n",
    "\n",
    "    y_pred_train = model_grid.predict(X_train)\n",
    "    y_pred_test = model_grid.predict(X_test)\n",
    "\n",
    "\n",
    "    # log artifacts\n",
    "    mlflow.log_metric('f1_score', f1_score(y_test, y_pred_test))\n",
    "    mlflow.log_artifacts(\"artifacts\", artifact_path=\"model\")\n",
    "    mlflow.log_param(\"data_version\", \"00000\")\n",
    "    \n",
    "    # store model for model interpretability\n",
    "    joblib.dump(value=model, filename=lr_model_path)\n",
    "        \n",
    "    # Custom python model for predicting probability \n",
    "    mlflow.pyfunc.log_model('model', python_model=lr_wrapper(model))\n",
    "\n",
    "\n",
    "model_classification_report = classification_report(y_test, y_pred_test, output_dict=True)\n",
    "\n",
    "best_model_lr_params = model_grid.best_params_\n",
    "\n",
    "print(\"Best lr params\")\n",
    "pprint(best_model_lr_params)\n",
    "\n",
    "print(\"Accuracy train:\", accuracy_score(y_pred_train, y_train ))\n",
    "print(\"Accuracy test:\", accuracy_score(y_pred_test, y_test))\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_test)\n",
    "print(\"Test actual/predicted\\n\")\n",
    "print(pd.crosstab(y_test, y_pred_test, rownames=['Actual'], colnames=['Predicted'], margins=True),'\\n')\n",
    "print(\"Classification report\\n\")\n",
    "print(classification_report(y_test, y_pred_test),'\\n')\n",
    "\n",
    "conf_matrix = confusion_matrix(y_train, y_pred_train)\n",
    "print(\"Train actual/predicted\\n\")\n",
    "print(pd.crosstab(y_train, y_pred_train, rownames=['Actual'], colnames=['Predicted'], margins=True),'\\n')\n",
    "print(\"Classification report\\n\")\n",
    "print(classification_report(y_train, y_pred_train),'\\n')\n",
    "\n",
    "model_results[lr_model_path] = model_classification_report\n",
    "print(model_classification_report[\"weighted avg\"][\"f1-score\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save columns and model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list_path = './artifacts/columns_list.json'\n",
    "with open(column_list_path, 'w+') as columns_file:\n",
    "    columns = {'column_names': list(X_train.columns)}\n",
    "    pprint(columns)\n",
    "    json.dump(columns, columns_file)\n",
    "\n",
    "print('Saved column list to ', column_list_path)\n",
    "\n",
    "model_results_path = \"./artifacts/model_results.json\"\n",
    "with open(model_results_path, 'w+') as results_file:\n",
    "    json.dump(model_results, results_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL SELECTION\n",
    "\n",
    "Model selection involves choosing the most suitable statistical model from a set of candidates. In straightforward cases, this process uses an existing dataset. When candidate models offer comparable predictive or explanatory power, the simplest model is generally the preferred choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants used:\n",
    "current_date = datetime.datetime.now().strftime(\"%Y_%B_%d\")\n",
    "artifact_path = \"model\"\n",
    "model_name = \"lead_model\"\n",
    "experiment_name = current_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from mlflow.tracking.client import MlflowClient\n",
    "from mlflow.entities.model_registry.model_version_status import ModelVersionStatus\n",
    "from mlflow.tracking.client import MlflowClient\n",
    "\n",
    "def wait_until_ready(model_name, model_version):\n",
    "    client = MlflowClient()\n",
    "    for _ in range(10):\n",
    "        model_version_details = client.get_model_version(\n",
    "          name=model_name,\n",
    "          version=model_version,\n",
    "        )\n",
    "        status = ModelVersionStatus.from_string(model_version_details.status)\n",
    "        print(f\"Model status: {ModelVersionStatus.to_string(status)}\")\n",
    "        if status == ModelVersionStatus.READY:\n",
    "            break\n",
    "        time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting experiment model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['963873149639731999']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_ids = [mlflow.get_experiment_by_name(experiment_name).experiment_id]\n",
    "experiment_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m experiment_best \u001b[38;5;241m=\u001b[39m mlflow\u001b[38;5;241m.\u001b[39msearch_runs(\n\u001b[0;32m      2\u001b[0m     experiment_ids\u001b[38;5;241m=\u001b[39mexperiment_ids,\n\u001b[0;32m      3\u001b[0m     order_by\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetrics.f1_score DESC\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m      4\u001b[0m     max_results\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      5\u001b[0m )\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      6\u001b[0m experiment_best\n",
      "File \u001b[1;32mc:\\Users\\Frederik\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1189\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[1;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_axis(maybe_callable, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32mc:\\Users\\Frederik\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1752\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index by location index with a non-integer key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1751\u001b[0m \u001b[38;5;66;03m# validate the location\u001b[39;00m\n\u001b[1;32m-> 1752\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_integer(key, axis)\n\u001b[0;32m   1754\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_ixs(key, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32mc:\\Users\\Frederik\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1685\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_integer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1683\u001b[0m len_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis))\n\u001b[0;32m   1684\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m len_axis \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39mlen_axis:\n\u001b[1;32m-> 1685\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle positional indexer is out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "experiment_best = mlflow.search_runs(\n",
    "    experiment_ids=experiment_ids,\n",
    "    order_by=[\"metrics.f1_score DESC\"],\n",
    "    max_results=1\n",
    ").iloc[0]\n",
    "experiment_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './artifacts/model_results.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./artifacts/model_results.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      4\u001b[0m     model_results \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m      5\u001b[0m results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({model: val[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweighted avg\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m model, val \u001b[38;5;129;01min\u001b[39;00m model_results\u001b[38;5;241m.\u001b[39mitems()})\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[1;32mc:\\Users\\Frederik\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    283\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    284\u001b[0m     )\n\u001b[1;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './artifacts/model_results.json'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"./artifacts/model_results.json\", \"r\") as f:\n",
    "    model_results = json.load(f)\n",
    "results_df = pd.DataFrame({model: val[\"weighted avg\"] for model, val in model_results.items()}).T\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = results_df.sort_values(\"f1-score\", ascending=False).iloc[0].name\n",
    "print(f\"Best model: {best_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get production model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "prod_model = [model for model in client.search_model_versions(f\"name='{model_name}'\") if dict(model)['current_stage']=='Production']\n",
    "prod_model_exists = len(prod_model)>0\n",
    "\n",
    "if prod_model_exists:\n",
    "    prod_model_version = dict(prod_model[0])['version']\n",
    "    prod_model_run_id = dict(prod_model[0])['run_id']\n",
    "    \n",
    "    print('Production model name: ', model_name)\n",
    "    print('Production model version:', prod_model_version)\n",
    "    print('Production model run id:', prod_model_run_id)\n",
    "    \n",
    "else:\n",
    "    print('No model in production')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare prod and best trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model_score = experiment_best[\"metrics.f1_score\"]\n",
    "model_details = {}\n",
    "model_status = {}\n",
    "run_id = None\n",
    "\n",
    "if prod_model_exists:\n",
    "    data, details = mlflow.get_run(prod_model_run_id)\n",
    "    prod_model_score = data[1][\"metrics.f1_score\"]\n",
    "\n",
    "    model_status[\"current\"] = train_model_score\n",
    "    model_status[\"prod\"] = prod_model_score\n",
    "\n",
    "    if train_model_score>prod_model_score:\n",
    "        print(\"Registering new model\")\n",
    "        run_id = experiment_best[\"run_id\"]\n",
    "else:\n",
    "    print(\"No model in production\")\n",
    "    run_id = experiment_best[\"run_id\"]\n",
    "\n",
    "print(f\"Registered model: {run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_id is not None:\n",
    "    print(f'Best model found: {run_id}')\n",
    "\n",
    "    model_uri = \"runs:/{run_id}/{artifact_path}\".format(\n",
    "        run_id=run_id,\n",
    "        artifact_path=artifact_path\n",
    "    )\n",
    "    model_details = mlflow.register_model(model_uri=model_uri, name=model_name)\n",
    "    wait_until_ready(model_details.name, model_details.version)\n",
    "    model_details = dict(model_details)\n",
    "    print(model_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEPLOY\n",
    "\n",
    "A model version can be assigned to one or more stages. MLflow provides predefined stages for common use cases: None, Staging, Production, and Archived. With the necessary permissions, you can transition a model version between stages or request a transition to a different stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transition to staging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "\n",
    "def wait_for_deployment(model_name, model_version, stage='Staging'):\n",
    "    status = False\n",
    "    while not status:\n",
    "        model_version_details = dict(\n",
    "            client.get_model_version(name=model_name,version=model_version)\n",
    "            )\n",
    "        if model_version_details['current_stage'] == stage:\n",
    "            print(f'Transition completed to {stage}')\n",
    "            status = True\n",
    "            break\n",
    "        else:\n",
    "            time.sleep(2)\n",
    "    return status\n",
    "\n",
    "model_version_details = dict(client.get_model_version(name=model_name,version=model_version))\n",
    "model_status = True\n",
    "if model_version_details['current_stage'] != 'Staging':\n",
    "    client.transition_model_version_stage(\n",
    "        name=model_name,\n",
    "        version=model_version,stage=\"Staging\", \n",
    "        archive_existing_versions=True\n",
    "    )\n",
    "    model_status = wait_for_deployment(model_name, model_version, 'Staging')\n",
    "else:\n",
    "    print('Model already in staging')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
